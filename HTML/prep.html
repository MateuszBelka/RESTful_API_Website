<!DOCTYPE html>
<html>
	<head>
		<title>Preparation Questions</title>
		<style>
		ol.alphabet {
			list-style-type: lower-alpha;
		}
		</style>
	</head>
	<body>
    <h1>Browser Compatability Report</h1>
		<p>
      First, we decided which browsers we will use for opening our website. Due to different browsers' limitations, not all of the existing one have a capacity to reveal all the CSS's properties. We used the most popular one - Safari(Apple) and Google Chrome. We discovered few differences:
      <ol>
        <li>
          Safari cannot display abbreviation's meaning; In Google Chrome you can do that;
        </li>
        <li>
          The font is bold in Safari in comparison to Google Chrome;
        </li>
        <li>
          The table is cut the way that half of the picture and name of the Bestseller's product is not visible(Safari);
        </li>
        <li>
          The third input's field does not display the calendar for choosing data(Safari).
        </li>
      </ol>
      However, using Handheld CSS style on mobile versions of Chrome and Safari no differences were found.
    </p>
    <h1>Preparation Questions LAB1</h1>
		<ol>
			<li>
				As W3C tries to keep relevancy infield they abandoned in 2004, they take the works of WHATWG and altering them in a way their original creators don&apos;t like it for the sake of making their work as a W3C recommendation. WHATWG calls these changes <q>forks</q>.
			</li>
			<li>
				Using two separate sources we understood the distinction between the Internet and the Web. According to W3C website<sup><a href="#fn1" id="ref1">1</a></sup>, Web is understood to be <q>...universe of network-accessible information […] The Web has a body of software...</q>. As stated by Internet Society (ISOC), Internet <q>is a widespread information infrastructure</q><sup><a href="#fn2" id="ref2">2</a></sup>. To conclude from those two statements we understand the interconnected nature of those two systems as the Web is a software which allows the user to access information through the medium of the internet which is the physical connection between computers.
			</li>
			<li>
				The uniqueness of Tim Berners-Lee’s Web comes from the general principles standing behind his idea. The three essential technologies of Web are: Locating documents through Uniform Resource Locators, Document representation using Hypertext Markup Language and Communication via Hypertext Transport Protocol.<sup><a href="#fn3" id="ref3">3</a></sup>
			</li>
			<li>
       Changes: in DOCTYPE declaration - info about HTML version, in head - CSS style declared, information about software, creation date and last changed date, in body - declaration of the language, direction of the text.
			</li>
			<li>
				<table id="protocolTable">
 					<tr>
  		 				<th>Protocol</th><th>Protocol Name</th><th>Port Number</th><th>Description</th>
					</tr>
					<tr>
		   				<td>HTTP</td><td>HyperText Transfer Protocol</td><td>80</td><td>Hypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML.It was designed for communication between web browsers and web servers, but it can also be used for other purposes. We trust the website(https://developer.mozilla.org/bm/docs/Web/HTTP) because it is the learning area that was created by Mozilla Corporation that cooperate and integrates development of Internet-related applications. </td>
					</tr>
 					<tr>
   		   				<td>SSH</td><td>Secure Shell</td><td>22</td><td>The SSH protocol (also referred to as Secure Shell) is a method for secure remote login from one computer to another. It provides several alternative options for strong authentication, and it protects the communications security and integrity with strong encryption. We believe that the source that we used(https://www.ssh.com/ssh/protocol/) because the website is "the home page for the SSH protocol, software, and related information." </td>
 					</tr>
 					<tr>
   		     	   				<td>FTP</td><td>File Transfer Protocol</td><td>20</td><td>FTP is the most widely used standart protocolor for  exchanging files and programs with another computer via Internet. The information we used is from the https://libguides.vu.nl/srch.php?q=ftp&amp;guide_id=410065 page and we believe that we can trust the source as it is VU Amsterdam library website.</td>
					</tr>
				</table>
			</li>
			<li>
				&lt;b&gt; is explicit such that it tells the browser that the text should be bold. &lt;strong&gt; is semantic. It leaves room for interpretation from the browser perspective. It simply states that the text in the tag should be <q>stronger</q> than the normal text. It allows changes to what it exactly means for actual styling through CSS. The ability to be flexible makes this preferable choice in modern web design. A similar case is with &lt;i&gt; and &lt;em&gt;.
			</li>
			<li>
				div is a block element, span is inline. Both are used to group a piece of text. Depending on the size of the section you will choose the proper one.
			</li>
			<li>
				The biggest advantage of using CSS is the clarity of code it provides. CSS is meant for style while HTML should not be only used for the structure. The ability to separate structure from style allows for better readability of code for maintenance. CSS gives greater flexibility over the presentation of the webpage as it has more options for styling over HTML. CSS allows the user to change the style in the whole webpage with much more ease. As the complexity of projects increases the automated control over things is greatly appreciated as otherwise the final product is greatly exposed to bugs and the development time is extended.
			</li>
			<li>
				We expected the browser to ignore the second call to emphasize the text or override already existing option to emphasize text which either way gives the same result, being that all the text is in italic font style.
			</li>
			<li>
				Key differences between Chrome and Safari:
				<ol>
					<li>Chrome is developed by Google Inc and Safari - by Apple</li>
					<li>Chrome works on Windows while Safari (after Safari 5) doesn’t support Windows anymore</li>
					<li>Safari doesn’t support Linux</li>
					<li>Safari allows extensions from the 3<sup>rd</sup>  party sites</li>
					<li>Safari is more energy efficient</li>
				</ol>
			</li>
		</ol>
    <h1>Preparation Questions LAB2</h1>
    <ol>
      <li>
        The most prevalent accessibility error, which does not have ALT texts, corresponds with 1.1 WCAG guidelines - "Decoration, Formatting, Invisible: If non-text content is pure decoration, is used only for visual formatting, or is not presented to users, then it is implemented in a way that it can be ignored by assistive technology."<sup><a href="#fn4" id="ref4">4</a></sup>
      </li>
      <li>
        On the example of Facebook<sup><a href="#fn5" id="ref5">5</a></sup>, we found out that the WAVE Report informs a user about errors, alerts, features, structural elements, HTML and ARIA's property descriptions. Each of the sections shows what does each of them mean, error explanation and how to fix them.
      </li>
      <li>
        We checked 3 color combinations(FC - Foreground Colour, BC - Background Colour):
        <ol>
          <li>
            FC - #000000, BC - #FFFFFF;
          </li>
          <li>
            FC - #FFFFFF, BC - #000000;
          </li>
          <li>
            FC -  #FF0000, BC - #FFFFFF;
          </li>
        </ol>
        The results are shown in the third box and divided into a few categories: "Brightness Difference", "Colour Difference", "Are colours compliant?", "Contrast Ratio", "WCAG 2 AA Compliant", "WCAG 2 AA Compliant (18pt+)", "WCAG 2 AAA Compliant", "WCAG 2 AAA Compliant (18pt+)". "The tool will indicate that the colours pass the test if both the colour difference and the brightness difference exceed their threshold. It will indicate that it sort of passes if only one of the two values exceeds their threshold. And finally, it'll fail to pass if neither value exceeds its threshold. The tool will also indicate if the colours pass the newer WCAG 2.0 contrast ratio formula. The WCAG 2.0 formula differentiates between text smaller than 18pt text larger than 18pt (or text that is bold and larger than 14pt). For AA compliance, text should have a ratio of at least 4.5:1 (larger text, at least 3:1). For AAA compliance, text should have a ratio of at least 7:1 (larger text, at least 4.5:1)."<sup><a href="#fn6" id="ref6">6</a></sup>
        The results of 3 color combinations: 1.

        <ol>
          <li>
            Brightness Difference: (>= 125) 255
          </li>
          <li>
            Colour Difference: (>= 500) 765
          </li>
          <li>
            Are colours compliant?  YES
          </li>
          <li>
            Contrast Ratio  21
          </li>
          <li>
            WCAG 2 AA Compliant YES
          </li>
          <li>
            WCAG 2 AA Compliant (18pt+) YES
          </li>
          <li>
            WCAG 2 AAA Compliant  YES
          </li>
          <li>
            WCAG 2 AAA Compliant (18pt+)  YES
          </li>
        </ol>
        2. <ol>
          <li>
            Brightness Difference: (>= 125) 255
          </li>
          <li>
            Colour Difference: (>= 500) 765
          </li>
          <li>
            Are colours compliant?  YES
          </li>
          <li>
            Contrast Ratio  21
          </li>
          <li>
            WCAG 2 AA Compliant YES
          </li>
          <li>
            WCAG 2 AA Compliant (18pt+) YES
          </li>
          <li>
            WCAG 2 AAA Compliant  YES
          </li>
          <li>
            WCAG 2 AAA Compliant (18pt+)  YES
          </li>
        </ol>
        3. <ol>
          <li>
            Brightness Difference: (>= 125) 178.755
          </li>
          <li>
            Colour Difference: (>= 500) 510
          </li>
          <li>
            Are colours compliant?  YES
          </li>
          <li>
            Contrast Ratio  3.998
          </li>
          <li>
            WCAG 2 AA Compliant NO
          </li>
          <li>
            WCAG 2 AA Compliant (18pt+) YES
          </li>
          <li>
            WCAG 2 AAA Compliant  NO
          </li>
          <li>
            WCAG 2 AAA Compliant (18pt+)  NO
          </li>
        </ol>
      </li>
      <li>
        <p>Mobile native applications have higher performance as they are developed, using different programming languages depends on the mobile operating system. IOS platform - Objective-C, Swift languages; Android apps in Java, Kotlin. As a result, the native applications are more efficient because of better performance, higher speed, in comparison to web applications, and are compiled by APIs and "native" mobile platform programming language.
        </p>
      </li>
      <li>
        <p>
          The general idea behind internalization might sound simple at first, making the person quickly consider it as an obvious part of the software they are working on however it is a long well without the end. The number of exceptions and unique cases when it comes to writing, calendar, time zones and daylight savings, names and addresses grow exponentially as you expand your project to more cultures. The need to be cognizant of the realistic limitations of internalization are crucial for the proper implementation of it. Often such system has to be very limited, or otherwise, the development time would be expended for ridiculous time and the benefit from it would be only felt by the few while the costs of the development would hurt everyone. Internalization is a concept that sounds perfect on paper however is it a daunting task in real life and has to be undertaken carefully. <br />
          While adapting for another culture, region or language the first thing that is usually considered in the local writing system. Changing systems such that they support Unicode from ASCII can be a very difficult and time-consuming task if realized late into the development. It may also be needed to support other legacy character sets and encodings. It may seem to a naked eye that we are nearing the end of internalization however this is only the beginning. There are many other factors to consider. One of them being how Unicode based encodings can store the same text using a different combination of characters. This disruption needs also to be taken into account while programming systems such as sorting or passing of text. However, the issues with language don't end there. Some writing systems require special support. Many of the Asian languages can be written vertically which needs to be fully supported and preferably work in conjunction with traditional typesetting options. Text alignment and justification methods are different for those writing systems and again can be different for scripts like Thai and Tibetan. Not only standard alphabet has to be taken into account but also elements like emphasis, annotations and list numberings may vary from language to language. Languages from the middle-east are uniquely known for their mix of right-to-left and left-to-right text on the same line. Whenever the text is rendered is has to properly represent the direction of text throughout the document or system. Added to that there are not so obvious changes in different cultures such as symbols. The check mark means correct in many counties however in places like Japan it can be understood as incorrect. Outside of writing system, Japanese localization would also require conversion of such symbols to be properly understood by a group of people its aimed for.<br />
          As mentioned before the problem is not limited to the writing system but also things such as calendars and time zones. In those cases especially the number of exceptions becomes countless and things can very quickly spiral out of control. The most important aspect of internalization is keeping everything in check and being able to realistically plan the possible scope of such a system.
        </p>
      </li>
      <li>
        <p>
          IP address of www.few.vu.nl:130.37.164.154<br />
          IP address of www.cs.vu.nl: 130.37.164.154 (the same as www.few.vu.nl)<br />
          The IP becomes known to both source and receiver during the exchange of data. Using this knowledge the IP of a website can be obtained through Command Prompt (Windows) while establishing the connection to a website and requesting some information from it. The command used to get the desired information is: tracert [URL of the website].
        </p>
      </li>
      <li>
        <p>
          IPv6 is the latest version of the Internet Protocol, which is used to identify every device on the internet such that they can be located. Every individual device that is using the internet has to have such IP address. With the rapid expansion of the internet from the 2000s onward it could have clearly been expected that certain systems within the internet will need to be replaced by better version due to the rising demand. Since the internet operates through the system of locating the source and receiver, and because of the limited nature of 1s and 0s, the number of possible ways to uniquely identify a device is steadily reaching its breaking point. IPv4 has been created with the capability of having 4.3 billion unique addresses. That number is a hard limitation on how the system has been created and in case that limit is reached a brand new solution needs to be implemented. <br />
          In 1998 IETF has realized that and created the new version, the IPv6. The main feature of that version is the ability to store 340 trillion unique IP addresses and by that eliminating, for now, the fear of the limited number of IP addresses. However, that was not the only thing that has changed. NAT, Network address translation, is a tool which allows the division between private and public IP addresses which in turn allow a lot of devices to be represented by a single IP address outside of the local network. With the very limited space for IP's, that was a crucial part of IPv4. With IPv6 the number of IP addresses is so "limitless" that such method will not be required. Last, but not least, IPv6 also has simplified the header by moving all the unnecessary information and options to the end of the IPv6 header. That way the information contained in the first part of the header is adequate for a Router to take routing decision which in turn allow the quicker connection between source and receiver. <br />
          The price of IPv4 addresses is said to peak in 2018 and they will drop after the deployment of IPv6 passes 50%. According to Google, the world has 20% to 22% IPv6 adoption, however, in the US it is about 32%. With the continuing increase in demand for bandwidth and latency, the change to IPv6 seems like an obvious decision to take immediately, however such huge structual changed to take a long time. Fortunately, everything points to the future where IPv6 will be dominant which is definitely good news for everyday end users.
        </p>
      </li>
      <li>
        The most common subtypes of type text are:
        <ul>
          <li>
            text/plain
          </li>
          <li>
            text/html
          </li>
          <li>
            text/css
          </li>
          <li>
            text/javascript
          </li>
          <li>
            text/markdown
          </li>
        </ul>
        Website: https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types is the most authorative source we found that provides the complete list of MIME types.
      </li>
      <li>
        <p>
          The sixth HTTP method that was presented in the blog post<sup><a href="#fn7" id="ref7">7</a></sup> is called HEAD. HEAD is very similar to GET, however, there is a difference - HEAD does not have a response body. "The convention has been established that the GET and HEAD methods SHOULD NOT have the significance of taking an action other than retrieval. These methods ought to be considered "safe". This allows user agents to represent other methods in a special way so that the user is made aware of the fact that a possibly unsafe action is being requested." The authoritative source: https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html
        </p>
      </li>
      <li>
        bc9041de
      </li>
    </ol>
    <h1>Preparation Questions LAB3</h1>
    <ol>
      <li>
        After writing appropriate code in index.html using script tag we loaded in the webpage to see the contents of the console. We are using Google Chrome so we chose: options->more tools->Developer tools. Under the Console catergory we can find the outputs from console.log
      </li>
      <li>
        <pre>
&lt;body onload="myFunction()"&gt;
  &lt;script&gt;
    function myFunction() {
      document.body.style.backgroundColor = "red";
    }
  &lt;/script&gt;
&lt;/body&gt;
        </pre>
        <pre>
&lt;body&gt;
  &lt;script&gt;
    function myFunction(link) {
      link.style.color = "green";
    }
  &lt;/script&gt;
  &lt;a onclick="myFunction(this)" href="#"&gt;Test&lt;/a&gt;
&lt;/body&gt;
        </pre>
      </li>
      <li>
        <pre>
&lt;body&gt;
  &lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"&gt;&lt;/script&gt;
  &lt;script&gt;
    $(document).ready(function(){
      $(".jumpLink").click(function(){
        $(this).css({'color': 'green'});
      });
    });
  &lt;/script&gt;
  &lt;a class="jumpLink" href="#"&gt;Test&lt;/a&gt;
&lt;/body&gt;
        </pre>
        <p>
          The fundamental difference between those two is that JavaScript is a programming language while jQuery is JavaScript library.
          <br />
          Comparison of jQuery and JavaScript:
          <ul>
            <li>
              jQuery provides you with a nice framework to work efficiently while in JavaScript everything has to be done from the beginning, meaning that the final result can be more well tailored for your needs but it comes at the cost of time and ease of use.
            </li>
            <li>
              jQuery simplifies HTML document traversing, event handling, animating and AJAX interactions.
            </li>
            <li>
              Since the internet as we know it today was created with JavaScript in mind there is no need to initiate it in any way because all modern browsers support it. jQuery on the other hand requires the jQuery library URL to be included in the header of the page.
            </li>
          </ul>
        </p>
      </li>
      <li>
        Python - a scripting, high-level programming language with dynamic semantics and object-oriented programming. Java-Script is an object-oriented programming language for creating dynamic web pages.
        Main differences between Python and Java-Script:
          Python:
        <ol>
          <li>Supports functional programming, object-oriented, imperative and procedural programming.
          </li>
          <li>Available on MAC and Linux by default
          </li>
          <li>No need for using libraries
          </li>
          <li>Used mainly by data scientists
          </li>
        </ol>
          Java-Script:
          <ol>
          <li>Supports functional, object-oriented and imperative programming as Python, however, not procedural programming.
          </li>
          <li>Available on all browsers
          </li>
          <li>Plenty of libraries for different reasons: DOM-orientated, graphical/vizualization and so on.
          </li>
          <li>Used by software developers.
          </li>
          </ol>
      </li>
      <li>
        AJAX stands for Asynchronous JavaScript and XML. That means a group of inter-related technologies, which are used for creating faster and more interactive web applications, such as XML, HTML, CSS, and Java Script. Asynchronous means that the browser doesn't refresh the web page when small amount of data has changed. AJAX passes the updated information to and from the server.
      </li>
      <li>
				Host objects are the objects which are created and provided to JavaScript by the environment (host). Depends on the hosting environment, the result of executed code may differ.
				Windows and documents are the most popular and used one. Python and Java don't require host environment in general. As follows, there are no host objects needed.
      </li>
      <li>
        <dl>
					<dt>String object</dt>
					<dd>String object can be used to get variaty of information about or minupulate the contents of the array of characters. Such as: get length, convert string to uppercase letters, etc.</dd>
					<dt>Date object</dt>
					<dd>The date object is used to work with dates and times. This object can be used to easily manipulate the initially declared date by using .setDate() function. This object also allows for comparison of dates among many other things.</dd>
				</dl>
      </li>
      <li>
        JavaScript in the browser uses event-driven programming model. HTML events are "things" that happen to the HTML elements and JavaScript can use this information to react upon noticing it. Event handlers (listeners) allow JavaScript to do exactly that. Making an action based on the detection of an event in HTML element.
      </li>
      <li>
        The Place Autocomplete service is a web service that returns place predictions in response to an HTTP request. The request specifies a textual search string and optional geographic bounds. The service can be used to provide autocomplete functionality for text-based geographic searches, by returning places such as businesses, addresses and points of interest as a user types.<sup><a href="#fn8" id="ref8">8</a></sup>
      </li>
      <li>
        <pre>
&lt;head&gt;
	&lt;script src="https://code.jquery.com/jquery-1.12.4.js"&gt;&lt;/script&gt;
	&lt;script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"&gt;&lt;/script&gt;
	&lt;script&gt;
		$( function() {
			var state = true;
			$( "#button" ).on( "click", function() {
				if ( state ) {
					$( "#effect" ).animate({
						backgroundColor: "Black",
						color: "White"
					}, 1000 );
				} else {
					$( "#effect" ).animate({
						backgroundColor: "Cornsilk",
						color: "Black"
					}, 1000 );
				}
				state = !state;
			});
		} );
	&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
	&lt;div class="toggler"&gt;
		&lt;div id="effect"&gt;
			&lt;h2 class="ListsTitle"&gt;
				Why should you choose us?
			&lt;/h2&gt;
		&lt;/div&gt;
	&lt;/div&gt;
	&lt;button id="button">Toggle Effect&lt;/button&gt;
&lt;/body&gt;
				</pre>
      </li>
    </ol>
    <h1>Preparation Questions LAB4</h1>
    <ol>
			<li>
				&nbsp;
				<ol class="alphabet">
					<li>
	        	We believe that tokenizer has done what it was supposed to do, such that: got the string of characters, grouped them in words and outputed a stream of these words.
						However, tokenizer's work could be improved by adding a qualifier that will be able to distinguish and categorize different language constructions in groups, for example idioms, phrases - in "phrasal" group, adjectives and adverbs - in "descriptive" group.
	      	</li>
	      	<li>
	        	According to the result of our function, we can see that almost all the common words are stop words or pronouns and that does not show all the diversity in the language. So, having the list of the actually most used nouns, adjectives and so on, we will be able to see the real vocabulary that the author used in his composition.
	      	</li>
	      	<li>
						<p>
		        	Following the definition of Zipf's law as presented to students through lecture slides, "Alice in the Wonderland" does follow Zipf's law. By that it is meant that the frequency matrix of words does follow the following rule: "the frequency of a word is inversely proportional to its rank in the frequency table.". Strictly speaking there is no way of providing an equation which would perfectly connect all the points of data in an inversely proportional manner however the results are close enough to accept the random error in empirical data and conclude that data presented to us from "Alice in the Wonderland" follows Zipf's law.<br/>
							By error I meant that if the results truly followed the Zipf's law they would go as such:
							<pre>
1644*1  =  1644
872*2   =  1744
729*3   =  2187
632*4   =  2528
595*5   =  2975
							</pre>
							however as the graph presents the general behaviour and principle of relative difference between the top 30 is preserved.
						</p>
	      	</li>
	      	<li>
	        	Following the definition of Heaps' law as presented to students through lecture slices, "Alice in the Wonderland" does follow Heaps' law. By that is meant that as larger parts of the source material as analyzed, fewer new words are found. That concludes in a data structure where the small piece of text has a lot of unique words while large pieces of text have a lot of them repeating, meaning proportionally less unique words compared to the size of the text.
	      	</li>
				</ol>
			</li>
			<li>
				&nbsp;
      	<ol class="alphabet">
	      	<li>
						TF-IDF is  a technique that consists of TF and IDF. TF - Term's Frequency and IDF - Inverse Document Frequency. The higher the TF-IDF score, the rarer the word in the text. We checked words "creature" and "footman". "Creature" was met 4 times amd its weight is from 1.3 to 2.59, depends on the chapter. "Footman" was met 14 times and its weight is 6.95. After manually check, we came to the conclusion that the precision and recall are high because both variants are correctly counted by the program.
	      	</li>
					<li>
	        	In TFIDF matrix the program not only has to evaluate how often a word is found in the text but also the frequency at which said word is found. The amount of computation needed is therefore increased and because of that the time it takes to acquire TFIDF matrix.
	      	</li>
	      	<li>
						<p>
		        	TF-based search presents information about the total number of times a word is found in the text while TFIDF search shows the weight of the word in the document based on how we exactly define it. TFIDF provides more detailed information about the words in the document hence we believe it is of higher quality than only TF-based search.<br/>
							There is always precision/recall tradeoff. If one is increased the other one is decresed.
							TF: Since stop words will be counted as important precision will be low however recall will be good as stop words do not exclude proper matches.<br/>
							TFIDF
						</p>
	      	</li>
	      	<li>
						TF will show 5 most common words from the text. TF-IDF will show us the 5 most weighted (=important) words in the text.
	      	</li>
	      	<li>
	      		Recall might increase since its function is to show the percentage of total relevant results correctly classified by the program.
	      	</li>
    		</ol>
			</li>
		</ol>
		<h1>Preparation Questions LAB5</h1>
			<ol>
				<li>
					&nbsp;
					<ol>
						<li>
							Idempotence, in this context, means that the side-effects of identical requests are the same as for a single request. GET method is idempotent.
						</li>
						<li>
							HTTP caching is available for idempotent results as the outcome will always be the same. That means that the request can be repeated automatically.
						</li>
						<li>
							We can see visitor statistics by using the GET method, which is idempotent. However, visitor counters might "break the system" due to the nature of being non-idempotent(changing) and it might lead to safety hesitation.
						</li>
						<li>
							Usually, proxy caches idempotent requests and, as we mentioned earlier, the visitor counter requires dynamic updates and changes. That might lead to safety confusion and wrong output.
						</li>
					</ol>
				<li>
					"Stateless protocol(no communication state) is a protocol in which every communication is handled as an independent event, unrelated to other similar communications.
          HTTP response should not depend on the previous request.
          HTTP GET method should be safe: no side-effects.
          HTTP POST should be used when multiple identical requests have a different effect than a single request.
          Other methods should be idempotent: requesting the same resource multiple times will yield the same result and no further side effects as a single request.
          REST simplifies global design and improves performance."(lecture slides)
				</li>
				<li>
					<p>
						Since web servers have no memory they are using specialized messages, cookies, which are stored on user's computers hard drive to store information such as login information but also for example shopping basket. This message exchange allows the server to know about previous activities done by the user without having to set up memory system alongside the web server.<br/>
            In the specific scenario of shopping basket, every time the user initiates an activity which is supposed to have an effect onto the shopping basket the server sends a message in a form of cookie to the users browser and later the browser sends that cookie back whenever the server needs to know the status of the shopping basket again. This way the server can easily get information about the state of the shopping basket without having to maintain memory.
					</p>
				</li>
				<li>
					<table cellspacing="10">
						<tr>
							<th>Company</th>
							<th>Endpoint</th>
							<th>HTTP method</th>
							<th>Response format</th>
							<th>HTTP response codes</th>
						</tr>
						<tr>
							<td>Twitter</td>
							<td><pre>https://api.twitter.com/1.1/statuses/user_timeline.json</pre></td>
							<td>GET</td>
							<td>JSON</td>
							<td>200</td>
						</tr>
						<tr>
							<td>Spotify</td>
							<td><pre>https://api.spotify.com/v1/albums/{id}</pre></td>
							<td>GET</td>
							<td>JSON</td>
							<td>200</td>
						</tr>
					</table>
				</li>
				<li>
        	The response that we receive after OPTIONS request informs us about another HTTP method that can be used on that URL. They are: GET, POST, PUT, DELETE, OPTIONS. The origin from which we can make those requests is "*" which means any number of characters which means that there is no limit to an origin.
			 </li>
				<li>
					Everything is as expected. Content-Type is JSON which we expected since coding in JavaScript. The answer has all the information that we want it to have in order to properly operate in our framework.
				</li>
				<li>
					After Auto Reloading is enabled it means that whenever the file which is responsible for running the server is updated, the browser webpage can be reloaded and it will display the updated information. In case any error is introduced it will also be visible if it will be activated after reloading the webpage.
				</li>
				<li>
					<p>
						Servers which use templates are preferable in cases of processes that the user's computer might experience problems such as lack of computational power. The large, complex operation might be better to be left for a server to tackle because otherwise, the user will have a negative experience with the system which can be avoided.<br/>
            Dynamically creating elements of the webpage on the clients' side is preferable in situations in which the output of the operation is vast and clients bandwidth is slow. Even in the case of smaller sizes of message the user might be expecting to have an immediate response from the website and latency might negatively affect users experience. Running code on clients side prevents those problems.
					</p>
				</li>
			</ol>
		<h1>Preparation Questions LAB6</h1>
			<ol>
				<li>
					"The social analysis of Web science must also deal with the negative aspects of Web-based social interaction (such as security breaches, identity theft, privacy violations, and the social disruptions of globalization). The Web produces such dangers because it provides opportunities for those who break laws, spread hate, or promote terrorism. These are troubling aspects of the Internet, so a responsible research agenda must include their study."<sup><a href="#fn9" id="ref9">9</a></sup> We believe that these problems cannot be solved by the effort of only Web Scientists or sociologists due do its complexity. Only working together they can find a solution to this problem.
				</li>
				<li>
					The long tail is a strategy that allows getting profit by selling "hard-to-find" items in small quantities to many customers instead of selling big amounts of a reduced number of high-demand items. The long tail is profitable because of its 3 cost-control strategies: promoting the "back" catalogue (using recommendation engines), items that take a longer time to use and by encouraging customers to put off using their products.
				</li>
				<li>
					<ol class="alphabet">
						<li> Net neutrality is the rule which states that all providers treat all data(websites, users, content) the same way without discrimination. I agree with Sir Tim that net neutrality is one of the most important principles on which whole World-Wide Web should be based on among others.
						</li>
						<li> That gives justice and feeling of equality to people who use the Internet and prevent them from the dishonesty of providers(slowing down traffic, charge users for content and so on).
						</li>
						<li> FCC is a Federal Communication Commission that is located in Washington, US. In 2015 European Parliament and Council made a regulation:"Regulation (EU) 2015/2120 of the European Parliament and of the Council of 25 November 2015 laying down measures concerning open internet access and amending Directive 2002/22/EC on universal service and users’ rights relating to electronic communications networks and services and Regulation (EU) No 531/2012 on roaming on public mobile communications networks within the Union." Until that treaty is in force, FCC ruling in US should not affect consumers in  European Union.
						</li>
					</ol>
				</li>
				<li>
					The role of the data.gov(and data.overheid.nl) is to make government data more transparent and accessible to citizens. The potential danger of these websites is lack of privacy and misexplanation of the data presented.
				</li>
				<li>
					<ol>
						<li>
							Since 2011 there has been a huge search engine optimization. The most popular one, Google, is suitable for use by advanced users and novice ones. The auto-correction system is one of the biggest advances as it is capable of predicting what user is actually trying to look for and suggest it for him. Search engines have also additional functionalities like searching within the only specific website or file format but also to force the engine to take into account elements of search query it is trying to avoid by itself (eg. %).
						</li>
						<li>
							PDF has improved dramatically and from personal experience is the desired file format for browsing the specific type of information. I have yet to encounter a poor use of PDF such that I would prefer to see normal HTML website. PDF has a specific use and if they are limited only to that they serve their purpose in the World Wide Web. Also, the navigation throughout a PDF file is also a non-existent issue in 2019 and a lot of similar features have to improve or introduced to support the use of PDF.
						</li>
						<li>
							Changing link colours is an incredibly standard thing that beginners learn so it is no longer an issue.
						</li>
						<li>
							The design part of creating a webpage has been a huge aspect of development from small projects to huge ones. The tools that are not available to beginners are allowing them to quickly learn how to make a readable webpage and the importance of it is often reminded.
						</li>
						<li>
							The flexibility of CSS allows the web developers to properly adjust the font size appropriately to the device the user is using. Because of that a good web design never experiences such issues.
						</li>
						<li>
							The maximizing the Search Engine Visibility is a vital part of web design and is always taken care of with caution.
						</li>
						<li>
							Ads became universally hated part of web experience and designers know exactly how to make the contents of their page visibly stand out from them.
						</li>
						<li>
							The standards within the web design industry had a lot of time to form and popular practices are well-known and followed by everybody.
						</li>
						<li>
							The practice of opening a new browser window is non-existent. However, the way users interact with the internet has also changed and because of that opening, a new browser tab may be a desirable outcome of some actions.
						</li>
						<li>
							Sellers have learned throughout the years what is the desired information of their websites and they follow those criteria carefully. They are well aware of what the users are looking for in their websites and they provide this information.
						</li>
					</ol>
					The mistakes listed on that website still stand however the difference is that the standards for good website have increased and the issues that are listed here are encountered rarely while browsing the internet. I would say that the top 10 list is still relevant and everyone in the industry should be cognizant of those bad practices even though it became a norm to avoid them.
				</li>
				<li>
					We picked the website: https://techcrunch.com/ Our A/B test is aimed to improve the number of advertisement offers the company gets. We aim to achieve that by changing the colour of the Advertise button to black. The first version will maintain the current design while the second version varies by the colour of the Advertise button. The dependent variable, which measures the performance, will be the number of advertisement offers and the independent variable will be the font colour of the Advertise button. Our hypothesis is that since the button will stand out, more people will click on it and the company will get more advertisement offers.
				</li>
				<li>
					Answers for each question: 1.Strongly disagree 2.Disagree 3.Neither agree nor disagree 4.Agree 5.Strongly agree
					<table cellspacing="10">
						<tr>
              <th>Question</th>
              <th>5</th>
              <th>4</th>
              <th>3</th>
              <th>2</th>
              <th>1</th>
            </tr>
						<tr>
							<td>Are you likely to recommend our products to your friends and family?</td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
						</tr>
						<tr>
							<td>Did our services satisfy your needs?</td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
						</tr>
						<tr>
							<td>Do you think the pricing was appropriate to the quality of services?</td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
							<td><input type="radio" /></td>
						</tr>
					</table>
					Our survey aimed to measure customer satisfaction and we found that the best and also the most common way to do that is to present a user with easy to operate 1 to 5 scale together with short questions. This way of introducing a survey to a user is very inviting and easy to complete, which we hope would lead to a high number of completed surveys.
				</li>
				<li>
					<p>
						Common Log Format helps developing Web log analysis software because it is a standardized format meaning that files can be read analyzed by a variety of web analysis program without the needs to convert the format of the file to different one. This consistency allows people to develop an additional feature of existing software of new software with more ease. <br/>
            Selecting where and how websites (especially complex ones) should be interconnected via hyperlinks can be a difficult task for a human editor. Because of that use of logs is a desirable path to pursue. Introduction of server logs allows for gathering information about which links are being used and furthermore give implicit information where potential links would be useful. <br/>
            The dependent variable would be a number of times users click specific links and independent variable would be the position and structure of links on the webpage. The hypothesis would be that links which are not desirable would not be clicked often by the users as represented by the log data.
					</p>
				</li>
				<li>
					11.11.1998 Google.com was crawled first 4 times by the Wayback Machine. In 1999 there were few pauses when it wasn't updated for a while(from June to September including and from December 1999 to January 2000). At first, it looked like the simplest website without any images, interactions. Later(April 1999) it looked like the Google that we know now: Google letters in the middle of the page, searching engine and button "I'm feeling lucky". In October 2000, Google has already 1,060,000,000 web pages and has language and display options enabled for choosing. In July 2001 Google is a trademark that is open for cooperation and has 1,346,966,000 web pages for searching. In 2002 Google allows you to make an image search, groups, news and use Google within specific topics. In 2003 - 3,307,998,701 web pages! In 2004 Google offers advertising programs, business solutions, Google tools and 4,285,199,774 web pages. In September 2005, Google offers 8,168,684,336 web pages, improved Advanced search and expanded Google Services: Answers, Catalogs, Labs, University Search and so on, and Google Tools: Blogger, Picasa, Talk, Earth and so on. In 2006 the tools for Web Developers are added, Maps, Video, Desktop, Gmail, Translate and opportunity to use Google on your mobile: SMS, maps and Google search. In 2007, Google started implementing pictures on their main searching bar such that whenever there is someone's Birthday or celebration, it will show the picture, with decorated "Google" word, related to the event. After clicking on this picture, a user can get all information about the event, for example, 1st of November 2007 - Halloween on the Web! At the beginning of 2008, Advanced Search looks completely different. Now, you can find web pages that include or does not include a particular word/phrase on the page. Google becomes more and more sensitive to the information is searched, gives more opportunities to find something very specific. Google offers Book, Code, Scholar, News archive, different operating systems(Linux, Apple, Microsoft), Shopping search. In 2009 - Google Bar with advanced web page translation, messages under a searching bar with tips and updates. In 2010 - updated picture of Google word above the searching bar, better design of the page, Google Voice is implemented. There are a lot of features are implemented from 2010 till now, but overall from the "birth" of Google till now there were 545.907 captures and this number was, is and will be increasing throughout the whole history of Google.
				</li>
			</ol>
		<hr></hr>
		<pre>
<sup id="fn1">1. <a href="https://www.w3.org/WWW/">https://www.w3.org/WWW/</a></sup>
<sup id="fn2">2. <a href="http://www.cs.ucsb.edu/~almeroth/classes/F04.176A/handouts/history.html">http://www.cs.ucsb.edu/~almeroth/classes/F04.176A/handouts/history.html</a></sup>
<sup id="fn3">3. <a href="https://www.w3.org/People/Berners-Lee/">https://www.w3.org/People/Berners-Lee/</a></sup>
<sup id="fn4">4. <a href="https://www.w3.org/TR/2008/REC-WCAG20-20081211/#text-equiv-all">https://www.w3.org/TR/2008/REC-WCAG20-20081211/#text-equiv-all</a></sup>
<sup id="fn5">5. <a href="https://www.facebook.com">https://www.facebook.com</a></sup>
<sup id="fn6">6. <a href="http://snook.ca/technical/colour_contrast/colour.html">http://snook.ca/technical/colour_contrast/colour.html</a></sup>
<sup id="fn7">7. <a href="http://www.jeffknupp.com/blog/2014/03/12/what-is-a-web-server/">http://www.jeffknupp.com/blog/2014/03/12/what-is-a-web-server/</a></sup>
<sup id="fn8">8. <a href="https://developers.google.com/places/web-service/autocomplete">https://developers.google.com/places/web-service/autocomplete</a></sup>
<sup id="fn9">9. <a href="http://www.cs.umd.edu/~ben/ShneidermanCACM6-2007.pdf">http://www.cs.umd.edu/~ben/ShneidermanCACM6-2007.pdf</a></sup>

		</pre>
	</body>
</html>
